# -*- coding: utf-8 -*-
"""
Created on 30 April 2019

This code process the forward runs to produce a dictionary containing historical 
diagnostics for each parcel.

Needs a subsequent script to collect the data and produce statistics

List of diagnostics:
    - integral of theta along the trajectory
    - min and max of theta along the trajectory
    - age (or life-time) of the parcel before exit
    - histogram of level to level transit in theta for each regions
    - minimum value of water vapour mixing rattio under last saturation hypothesis
    
The diagnostics are performed for two values of the max age (by defaut 30 or 62 days)
They are both stored in the same dictionary

Parameters: (essentially the same as for stat-forw-uniq)
--type: supertype of wind data used and domain used in this analysis
"EAD","EAZ","EIZ","EID","EIZ-FULL","EID-FULL"
--quiet: determines whether printed outputs go to a file or to the screen
--full: determines whether the domain is global, can only be used with EID-FULL and EIZ-FULL
--date: determines the run stream following the segmentation of the 
runs
["Jun-01","Jun-11","Jun-21","Jul-01","Jul-11","Jul-21","Aug-01","Aug-11","Aug-21"]
--age_max: age max (in days)
--age_max_inter: second age max, should be less than the first
--inc:  step inc for which the part file are processed

Output is in a pickle file containing the dictionary source
sources contains the information in the part_000 file (generated by prepforw5Box)
plus additional informations.
'theta': potential temperature of the parcel at launch
'alt': barometric altitude of the parcel at launch
'count': number of recorded steps for this parcel with age <= age_max
'count_inter': number of recorded steps for this parcel with age <= age_max_inter
'age': last age recorded which is less than age_max
'age_inter': last age recorded which is less than age_max_inter
'theta_mean', theta_mean_inter': theta accumulation along the trajectory
'theta_min, theta_min_inter': theta min along the trajectory
'theta_max, theta_max_inter': theta max along the trajectory
'rv_s, rv-s_inter': minimum value of mixing ratio under last saturation hypothesis

'veryhigh, silviahigh': flags indicating that parcels belongs to these groups

In addition we calculate 3D histograms 'hdisptheta, hdisptheta_inter' with
dimensions (20,20,25) where the first refers to the level of the parcel 
in the sampled step, the second to the initial level of the parcel and the
third to the region of origin. These histograms are based on mh hightype only.

vert = baro is not considered here

The parcels launched from the erroneous image on 30 August at 11 are eliminated.

8 October 2019: removal of spurious high altitude sources at high latitudes and Europe
not actually exploited yet

@author: Bernard Legras
"""

import os
import numpy as np
#from datetime import datetime, timedelta
import gzip, pickle
import sys
import resource
import argparse
import socket
import io107
from satratio import satratio
from zISA import z1,z2
import constants as cst
from numba import jit

# accelerator to calculate the 3d histogram (otherwise extremely slow)
@jit(nopython=True)
def accumul(hist,lev,lev0,regs):
    for i in range(len(lev)):
        hist[lev[i],lev0[i],regs[i]] += 1
    return

#%%
parser = argparse.ArgumentParser()
#parser.add_argument("-y","--year",type=int,help="year")
#parser.add_argument("-m","--month",type=int,choices=1+np.arange(12),help="month")
parser.add_argument("-t","--type",choices=["EAT","EAD","EAZ","EIZ-FULL","EID-FULL"],help="type")
#parser.add_argument("-v","--vert",choices=["theta","baro"],help="vertical discretization")
parser.add_argument("-q","--quiet",type=str,choices=["y","n"],help="quiet (y) or not (n)")
parser.add_argument("-f","--full",type=str,choices=["y","n"],help="full (y) or not (n)")
parser.add_argument("-d","--date",type=str,choices=["Jun-01","Jun-11","Jun-21","Jul-01","Jul-11","Jul-21","Aug-01","Aug-11","Aug-21"],help='run_date')
parser.add_argument("-am","--age_max",type=int,help="max age to be processed")
parser.add_argument("-ami","--age_max_inter",type=int,help="max intermediate age to be processed")
parser.add_argument("-i","--inc",type=int,help='step inc for processing')

# default values for the first start day
year = 2017
#month = 7
day = 1
vert = 'theta'
supertype = 'EAD'
water_path = True
quiet = False
target = 'FullAMA'
date = 'Jun-01'

# ages max in days
age_max = 62
age_max_inter = 30
step_inc = 6
#step_start=240
#step_end=240
step_start  = step_inc

args = parser.parse_args()
#if args.year is not None: year = args.year
#if args.month is not None: month = args.month
if args.type is not None: supertype = args.type
#if args.saf is not None:
#    if args.saf == 'O':
#        saf = ''
#if args.vert is not None: vert = args.vert
if args.quiet is not None:
    if args.quiet=='y': quiet=True
    else: quiet=False
if args.full is not None:
    if args.full=='y':
        target = 'global'
if args.date is not None: date = args.date
if 'FULL' not in supertype: target = 'FullAMA'
if args.age_max is not None: age_max = args.age_max
if args.age_max_inter is not None: age_max_inter = args.age_max_inter
if args.inc is not None: step_inc = args.inc
    
# derived times
#if date == 'Jul-21':
    #hmax = 24*(age_max + 11)
    #hinter = 24*(age_max_inter + 11)
#else:
hmax = 24*(age_max + 10)
hinter = 24*(age_max_inter + 10)
step_start = step_inc

print('target',target)

# other parameters 
#traj_dir = "/data/legras/flexout/STC/FORW"+saf    
#out_dir = "/data/legras/STC/STC-FORW"+saf+"-OUT"
traj_dir = "/data/legras/flexout/STC/FORWBox-meanhigh"    
if 'ciclad' in socket.gethostname():
    out_dir = "/data/legras/STC/STC-FORWBox-meanhigh-OUT"
elif ('climserv' in socket.gethostname()) | ('polytechnique' in socket.gethostname()):
    out_dir = "/homedata/legras/STC/STC-FORWBox-meanhigh-OUT"

#### Restart from sav of the previous run if interrupted 
#pile=pickle.load(gzip.open('pile2-sav-R.pkl','rb'))

#%% Central section
run_type = supertype+'-Box-'+vert+'-'+target
    
#pile_sav_name = os.path.join(out_dir,'pile-save-'+run_type+'.pkl')
history_stream = os.path.join(out_dir,'history-stream-'+run_type+'-'+date+'-h'+str(hmax)+'.pkl')

# Manage the file that receives the print output
if quiet:
    # Output file
    print_file = os.path.join(out_dir,'out','history-'+run_type+'-'+date+'.out')
    fsock = open(print_file,'w')
    sys.stdout=fsock
    
print("history-forw-uniq> process "+run_type+' '+date)

run_dir = os.path.join(traj_dir,'FORW-'+supertype+'-'+str(year)+'-'+date)
sources = io107.readpart107(0,run_dir)
IDX_ORGN = sources['idx_orgn']
if water_path :
    sources['rv_s'] = satratio(sources['p'],sources['t'])
    sources['rv_s_inter'] = satratio(sources['p'],sources['t'])
# barometric altitude of the source (not assumed to be above 55 hPa)
id1 = sources['p']>22632.#saf = 'N'
sources['alt'] = np.empty(sources['numpart'],dtype=np.float32)
sources['alt'][~id1] = z2(0.01*sources['p'][~id1])
sources['alt'][id1] = z1(0.01*sources['p'][id1])
# potential temperature of the source
sources['theta'] = (sources['t'] * (cst.p0/sources['p'])**cst.kappa).astype(np.float32)
# initialized live record
sources['live'] = np.empty(sources['numpart'],dtype=bool)
sources['live'].fill(True)
sources['age'] = np.zeros(sources['numpart'],dtype=np.float32)
sources['theta_mean'] =  np.zeros(sources['numpart'],dtype=np.float32)
sources['theta_max'] = np.zeros(sources['numpart'],dtype=np.float32)
sources['theta_min'] = np.empty(sources['numpart'],dtype=np.float32)
sources['theta_min'].fill(10000)
sources['count'] = np.zeros(sources['numpart'],dtype=np.int16)
sources['age_inter'] = np.zeros(sources['numpart'],dtype=np.float32)
sources['theta_mean_inter'] =  np.zeros(sources['numpart'],dtype=np.float32)
sources['theta_max_inter'] = np.zeros(sources['numpart'],dtype=np.float32)
sources['theta_min_inter'] = np.empty(sources['numpart'],dtype=np.float32)
sources['theta_min_inter'].fill(10000)
sources['count_inter'] = np.zeros(sources['numpart'],dtype=np.int16)
# veryhigh filter generating a boolean slice among initial points
ct = sources['flag'] >> 24
sources['veryhigh'] = (ct == 9) | (ct == 13)
#sources['silviahigh'] = ((ct == 9) & (sources['x']>90.75)) | \
#        (((ct==8)|(ct==9)|(ct==13)) & (sources['x']<=90.75))
sources['silviahigh'] = (ct == 9) | (ct == 13) | (ct == 8)
print("history-forw-uniq > date "+ date,np.sum(sources['veryhigh']),np.sum(sources['silviahigh']))

# prepair for the histogram
# read mask and initialize edges
# this mask has resolution 0.25Â°
with gzip.open(os.path.join('..','mkSTCmask','MaskCartopy2-STCfine.pkl'),'rb') as f: 
    mm =pickle.load(f) 
xedge = np.arange(-10,160+0.5*mm['icx'],mm['icx'])
yedge = np.arange(0,50+0.5*mm['icy'],mm['icx'])
minv = 322.5
maxv = 422.5
binv = 20
binvl = 5
vcent = np.arange(325,421,(maxv-minv)/binv)
sources['hdisptheta'] = np.zeros(shape=(binv,binv,len(mm['regcode'])+1),dtype=np.int32)
sources['hdisptheta_inter'] = np.zeros(shape=(binv,binv,len(mm['regcode'])+1),dtype=np.int32)
ix0 = np.floor((sources['x']-xedge[0])/mm['icx']).astype(np.int32)
jy0 = np.floor((sources['y']-yedge[0])/mm['icy']).astype(np.int32)
ix0 = np.clip(ix0,0,mm['nlons']-1)
jy0 = np.clip(jy0,0,mm['nlats']-1)
regs =( mm['mask'][jy0,ix0]).astype(np.int32)
lev0 = np.floor((sources['theta']-minv)/binvl).astype(np.int32)
lev0 = np.clip(lev0,0,binv-1)

# kill the sources of 30 August 2017 at 11h (227h)
if date == 'Aug-21':
    sources['live'][sources['ir_start'] == 3600*227] = False
#  filtering high lat / high alt (spurious sources above 360K at lat>40N)
sources['live'][(sources['theta']>360) & (sources['y']>=40)] = False
# additional filtering in the European region 
sources['live'][(sources['theta']>360) & (sources['y']>=35) & (sources['x']<40)] = False


# Loop on steps
for step in range(step_start,hmax + step_inc ,step_inc):
    print("history-forw> step "+str(step))
    # Read the nactive parcels at current step
    data = io107.readpart107(step,run_dir,quiet=True)
    # Get the list of indexes for the active parcels after removing the offset
    idxsel = data['idx_back']-IDX_ORGN
    # remove this field
    data['idx_back'] = []
    # Generate the list of ages of active parcels from their launch (in day)
    data['age'] = step/24 - sources['ir_start'][idxsel]/86400
    data['theta'] = data['t'] * (cst.p0/data['p'])**cst.kappa
    # Killing exited parcels if FULL in supertype and if target=FullAMA
    # The killed parcels remain killed afterwards, even if they re-enter the domain
    if ('FULL' in supertype) & (target == 'FullAMA'):
        selkill = np.any([data['x']<=-10,data['x']>=160,data['y']<=0,data['y']>=50],axis=0)
        idxkill = idxsel[selkill]
        sources['live'][idxkill] = False
    # Selecting parcels which are both of age less than the max age and have never left the FullAMA box
    # selage is a boolean array of dimension nactive
    selage = np.all([data['age'] <= age_max, sources['live'][idxsel] == True],axis=0)
    # A second filter is applied to intermediate age
    selage_inter = np.all([data['age'] <= age_max_inter, sources['live'][idxsel] == True],axis=0)
    # get rid of unused data
    data['x'] = data['y'] = []
    # Copy of data and reduction if the filter applies (only for the variables used in transit)
    if step <= hinter:
        data_inter = {}
        for var in ('theta','p','t','age'):
            data_inter[var] = data[var][selage_inter]
        idxsel_inter = idxsel[selage_inter]
    if np.all(selage) != True:
        for var in ('theta','p','t','age'):
            data[var] = data[var][selage]
        idxsel = idxsel[selage]
    
    # record history of the active parcels
    sources['count'][idxsel] += 1     
    sources['age'][idxsel] = data['age']
    sources['theta_mean'][idxsel] += data['theta']
    sources['theta_min'][idxsel] = np.min(np.array([sources['theta_min'][idxsel],data['theta']]),0)
    sources['theta_max'][idxsel] = np.min(np.array([sources['theta_max'][idxsel],data['theta']]),0)
    # fill histogram per source
    lev =  np.floor((data['theta']-minv)/binvl).astype(np.int32)
    lev = np.clip(lev,0,binv-1)
    lev0loc = lev0[idxsel]
    regsloc = regs[idxsel]
    accumul(sources['hdisptheta'],lev,lev0loc,regsloc)
    # dehydration    
    if water_path :
        sources['rv_s'][idxsel] = np.minimum(sources['rv_s'][idxsel],satratio(data['p'],data['t']))
    if step <= hinter:
        sources['count_inter'][idxsel_inter] += 1     
        sources['age_inter'][idxsel_inter] = data_inter['age']
        sources['theta_mean_inter'][idxsel_inter] += data_inter['theta']
        sources['theta_min_inter'][idxsel_inter] = np.min(np.array([sources['theta_min_inter'][idxsel_inter],data_inter['theta']]),0)
        sources['theta_max_inter'][idxsel_inter] = np.min(np.array([sources['theta_max_inter'][idxsel_inter],data_inter['theta']]),0)
        lev =  np.floor((data_inter['theta']-minv)/binvl).astype(int)
        lev = np.clip(lev,0,binv-1)
        lev0loc = lev0[idxsel_inter]
        regsloc = regs[idxsel_inter]
        accumul(sources['hdisptheta_inter'],lev,lev0loc,regsloc)
        if water_path :
            sources['rv_s_inter'][idxsel_inter] = np.minimum(sources['rv_s_inter'][idxsel_inter],satratio(data_inter['p'],data_inter['t']))    
    #pickle.dump(pile,gzip.open(pile_sav_name,'wb',pickle.HIGHEST_PROTOCOL))
    print('Memory used: '+str(resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)+' (kb)')
    del data
    sys.stdout.flush()
# save the pile to restart the run if needed
pickle.dump(sources,gzip.open(history_stream,'wb',pickle.HIGHEST_PROTOCOL))
    
# %%
# Final processing and save 
#pile_name = os.path.join(out_dir,'pile-'+run_type+'.pkl')
#pile.complete()        
#pickle.dump(pile,gzip.open(pile_name,'wb',pickle.HIGHEST_PROTOCOL))
#transit.transit_show(pile)
if quiet: fsock.close()
